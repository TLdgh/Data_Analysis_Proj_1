---
title: |
  | \vspace{-4em}MAT5314 Project 1: Data Visualization
author: 
  - Teng Li(7373086)
  - Shiya Gao(300381032) 
  - Chuhan Yue(300376046)
  - Yang Lyu(8701121)
output: 
  pdf_document: 
    keep_tex: true
    includes:
      in_header: columns.tex
fontsize: 11pt
header-includes: 
  - \renewcommand{\and}{\\}
  - \usepackage{float}
  - \floatplacement{figure}{H}
bibliography: References.bib
link-citations: yes
---

# Introduction
A data set of the 2016 US election polls was given. In this project we aim to understand the data structure by creating various visualizations.

First, we would like to give a brief introduction to the U.S. election system as it is crucial to understand the background of the data. Voters in each state vote to choose the President of the United States. The candidate who wins the majority of the votes will receive all the electoral votes in that state. Then the sum of the electoral votes in each state is calculated. The total number of electoral votes is 538. The candidate who wins half of the votes plus 1 will win and become the new President of the United States. Since each state has a different number of electoral votes, it is crucial for electors to win in several key states. The reason is that if a candidate wins a certain state, he will win all the electoral votes in that state. Texas, for example, counts for 38 electoral votes during the election, it is therefore a tight competition in states with more votes. 

Analysis on poll result can be very difficult due to the fact that carrying out a public opinion poll is generally difficult. The experimental design plays a profound rule in these surveys, as sometimes it is hard to achieve an unbiased sample. On the other hand, one might not be able to obtain the final result that can be compared with the poll result. Finally it can be very expensive to carry out a qualitative poll under budget constrains. However, election poll result is a desirable measurement we can study. Large institutions design the survey and gather public opinions. Moreover, we immediately know with high accuracy and details on who wins the election at the end. It is therefore worthy to analyze the poll results and make some inferences, perhaps even compare results between each election. Thus, we want to analyze some of the key factors given by our poll result data and compare with the actual election result for the candidateâ€™s victory.

# Method
The data set was published by FiveThirtyEight to illustrate the reliability and quality of each pollster to which a letter grade ranging from A+ to D- was given. We first analyzed key individual variables in the data, then we sought to draw conclusions on the relationship between some of the key variables. To achieve this, we use various R packages to present the data set and to plot the graphs.

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
library(plotly)
library(tidyverse)
library(kableExtra)
library(maps)
library(htmlwidgets)
library(webshot)
```

# Section 1: Data Dictionary
```{r}
#load data set
ElectionPoll<-read.csv("polls_us_election_2016.csv", header = TRUE)
```

We first created a data variable definition table to give an initial understanding of the data. We formed the table by collecting each variable from the data, listed in the Variables column. We then looked at the size and the data type of each variable to understand its nature. An example consisting of a few variable values was given to illustrate what the variable might look like. We then calculated the number of unique and missing values in each variable. As one can see, there were a few variables with high percentage of missing values, for which we have discussed further in details in the subsequent sections. Finally, we gave a comment for each variable to briefly explains what it means and what it represents. The data dictionary is listed in Table 1:

```{r}
#create data variable definition
DataDict<-data.frame(
  Variables=colnames(ElectionPoll), Size=nrow(ElectionPoll), 
  Type=sapply(ElectionPoll, function(x) class(x)),
  Example=sapply(ElectionPoll, function(x) paste(as.character(head(unique(x),3)), collapse = ", ")),
  Number.Unique=sapply(ElectionPoll, function(x) length(unique(x))),
  Number.Missing=sapply(ElectionPoll, function(x) sum(is.na(x))),
  Comment=c("The name of the state (or national) where the election is held",
            "Start date of poll",
            "End date of poll",
            "Organization name that conducts or analyzes opinion polls",
            "Grade assigned by Fivethirtyeight to pollster",
            "Sample size of polls for each pollster",
            "Type of population being polled",
            "Poll Percentage for Hillary Clinton",
            "Poll Percentage for Donald Trump",
            "Poll Percentage for Gary Johnson",
            "Poll Percentage for Evan Mcmullin",
            "Adjusted percentage for Hillary Clinton",
            "Adjusted percentage for Donald Trump", 
            "Adjusted percentage for Gary Johnson",  
            "Adjusted percentage for Evan Mcmullin")
)

DataDict%>%remove_rownames()%>%kable(booktabs = TRUE,caption = "Data Variable Definition")%>%
  kable_styling(font_size=10, latex_options=c("striped","scale_down","hold_position"))%>%
  column_spec(4, width = "8em")%>%
  row_spec(0,bold=TRUE)

Jmiss<-sapply(ElectionPoll[, c("rawpoll_johnson", "adjpoll_johnson")], function(x) round(sum(is.na(x))/nrow(ElectionPoll)*100,2)%>% paste0("%") ) 
Jmc<-sapply(ElectionPoll[, c("rawpoll_mcmullin", "adjpoll_mcmullin")], function(x) round(sum(is.na(x))/nrow(ElectionPoll)*100,2)%>% paste0("%") ) 
```

Note that the poll results for Johnson and McMullin had lots of missing values. In particular, Johnson had `r Jmiss[1]` raw poll result and  `r Jmiss[2]` adjusted poll result missing, and McMullin had `r Jmc[1]` and `r Jmc[2]` missing. Due to the fact that these two candidate didn't make to the final election, and the percentage of missing values is too high to be considered in the analysis, we chose to ignore their data in some of the analysis below. 

# Section 2: Variable Exploration
We first took an initial look at each variable.

### State
The state variable consists of each state in the U.S., but it also contains the national value named "U.S." and some of other values like "Maine CD-1":

```{r}
set.seed(100)
unique(ElectionPoll$state)[sample(1:57, 6)]
```

Maine CD-1 refers to the 1st Congressional District of the state of Maine in the United States. In the U.S., each state is divided into congressional districts for the purpose of electing members to the House of Representatives, which is one of the two chambers of the U.S. Congress. Maine, like most states, is divided into multiple congressional districts, and these districts are numbered.

Maine has two congressional districts: CD-1 and CD-2. CD-1 represents the 1st Congressional District while CD-2 represents the 2nd Congressional District. Each district elects one member to the U.S. House of Representatives. This district, like others across the country, participates in the election of a U.S. Representative who will represent the interests of the constituents living within that particular district in the federal government. 

In our analysis, the votes from these distinct districts might or might not be presented separately to the main State. Sometimes for simplicity we will combine all votes in the state to represent the overall poll opinion.


### Start and End Date
The startdate and enddate variables correspond to the dates on which the public opinion poll was initiated and finalized respectively. Individual pollster might start or end their poll at different date than other pollsters.

### Grade
We then took a look at the grade variable. We noticed that there are 57 pollsters (almost 30% of the total number of pollsters) whose grades are missing in this data set. Although the grades were missing, we could not just omit them because there were data in other columns. For example:

```{r}
head(ElectionPoll[which(is.na(ElectionPoll$grade)==TRUE), c("state", "grade", "rawpoll_clinton")], 2)
```

:::::: {.cols data-latex=""}

::: {.col data-latex="{0.53\textwidth}"}
We suppose that there are two possible reasons for these missing data: one is that there are some errors of data in the original file; the other is that fivethirtyeight has not rated these pollsters yet. So we searched online and found a more detailed and authoritative file about the pollsters' grade from the fivethirtyeight website.[@MissingD]

\vspace{13pt}

If one had omitted the NA from the grade by rows, then the available data from other variables would be omitted as well, which affects the final result and may yield incorrect inference to the data. Therefore, we will only delete a variable entirely if it has most of its values missing. Dividing the variable (column) will not affect values in other variables like omitting NA by rows.

\vspace{13pt}

According to the fivethirtyeight website, we found that 26 pollsters with no grade in the origin data set actually have the grades like "A/B", "B/C", "C/D", "B", "B-"; otherwise, the rest 31 pollsters without grades haven't been scored yet. Based on these information, we updated the "grade" column of the origin data set. We replace "NA" with the actual grades and "none". The result was presented in Table 2.
:::

::: {.col data-latex="{0.02\textwidth}"}
\ 
<!-- an empty Div (with a white space), serving as
a column separator -->
:::

::: {.col data-latex="{0.45\textwidth}"}

```{r, results='asis'}
ElectionPoll$grade[is.na(ElectionPoll$grade)] <- "none" #Replace NA in the "grade" column with none
condition1 <- ElectionPoll$pollster %in% c("Associated Industries of Florida", "BK Strategies", "Baldwin Wallace University", "Bendixen & Amandi International", "Centre College", "Craciun Research", "Data Targeting", "Hickman Analytics", "HighGround", "Insights West", "Mercyhurst University", "Meredith College", "Ogden & Fry", "Praecones Analytica", "Saguaro Strategies", "Starboard Communications", "Strategic National", "Strategy Research", "University of Colorado") #Replace the right grades with none
ElectionPoll$grade[condition1] <- "B/C"
condition2 <- ElectionPoll$pollster %in% c("Data Orbital", "Echelon Insights", "Michigan State University", "Public Religion Research Institute")
ElectionPoll$grade[condition2] <- "A/B"
condition3 <- ElectionPoll$pollster %in% c("Morning Consult")
ElectionPoll$grade[condition3] <- "B-"
condition4 <- ElectionPoll$pollster %in% c("Remington")
ElectionPoll$grade[condition4] <- "B"
condition5 <- ElectionPoll$pollster %in% c("University of Wyoming")
ElectionPoll$grade[condition5] <- "C/D"
A <- distinct(ElectionPoll[which(ElectionPoll$grade %in% c("A/B","B/C","C/D","Morning Consult","Remington")), c("pollster", "grade")])
cat("\\small")
kable(A, format = "markdown", 
      caption = "Updating the missing data",
      align = c("l", "c", "c")) %>%
  kable_styling(full_width = FALSE)
```
:::
::::::

\vspace{18pt} 

Because some pollsters are repeated in different rows of the data set, so we want to verify that each pollster corresponds to only one kind of grade. 
The result is as follow:
```{r}
#Calculate the different grades corresponding to each pollster
pollster_grade <- distinct(subset(ElectionPoll, select = c("pollster","grade"))) #Extract two columns:"pollster" and "grade" from the Electionpoll
grouped_data <- pollster_grade %>%
  group_by(pollster) %>%
  summarise(number_of_grades = n_distinct(grade))
unique_values <- unique(grouped_data$number_of_grades)
if (length(unique_values) == 1) {
  cat("the column of number_of_grades only contains one type of value:", unique_values, "\n")
} else {
  cat("the column of number_of_grades contains different types of values.\n")
}
```

After cleaning the missing values for the grade variable and checked its uniqueness for each pollster to make sure there was no error in data entry, we plotted a pie chart to gain initial understanding of the grade variable.

:::::: {.cols data-latex=""}

::: {.col data-latex="{0.48\textwidth}"}
From Figure 1: Pollster's Grade Distribution below, we could see that the unrated pollsters make up the largest percentage, about 15.8% of the total; pollsters with grades "B" and "C+" account for the second and third most, 12.8% and 12.2% respectively; "D" grade has the smallest percentage of pollsters, only about 0.51%. Besides, B-level grades, including "B+", "B" and "B-", are around 34.7%, almost one-third of the total; C-level and A-level grades are about 21.89% and 14.79% respectively. For those without explicit grades, whose grades are "A/B", "B/C" and "C/D", they account only for 12.24%, "B" grade pollsters make up the majority of this part especially, almost 9.69%.
:::

::: {.col data-latex="{0.02\textwidth}"}
\ 
<!-- an empty Div (with a white space), serving as
a column separator -->
:::

::: {.col data-latex="{0.5\textwidth}"}
```{r}
category_counts <- table(as.factor(pollster_grade$grade))
unique_levels <- levels(factor(pollster_grade$grade)) 
percentages <- (category_counts / sum(category_counts))*100 #calculate the percentages of different grades
A <- as.data.frame(percentages)#construct the data frame of two variables:"Var1"(grade) and "Freq"(percentages of grades)

piechart <- plot_ly(A, labels=~Var1, values=~Freq, type="pie", width = 500, height = 400)%>% 
  layout(margin=list(l=0, r=0, b=0, t=20),
         title = list(text="Pie Chart of Pollsters' Grades", font=list(size=10)),
         xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
         yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
         legend = list(title = list(text="Grade"),font=list(size=10))
  )

saveWidget(widget = piechart, file = "./Figures/piechart.html")
shots<-webshot(url = "./Figures/piechart.html", file = "./Figures/piechart.png", delay = 1, zoom = 2, vheight = 400, vwidth = 500)
```

![Pollster's Grade Distribution](./Figures/piechart.png){width=40%, height=30%}
:::
::::::

### Sample Size
Checking the sample size alone does not inform us much about the poll result. Instead, we take a look at the distribution of the sample size with regards to the grade. We sum up the sample size based on each grade level and made a bar plot:
\begin{minipage}[t]{0.55\textwidth}
```{r, warning=FALSE, out.width="100%", fig.cap = "Distribution of Sample Size for Grades"}
GradeVsSize<-ElectionPoll%>%group_by(grade)%>%summarise(Size=sum(samplesize))
GradeVsSize$grade<-factor(GradeVsSize$grade, levels=c("A+", "A", "A-", "A/B", "B+", "B", "B-", "B/C", "C+", "C", "C-", "C/D", "D", "none"))

sampleDist<-ggplot(GradeVsSize, aes(x=grade, y=Size))+
  geom_bar(stat="identity")+labs(title="Sample Size VS Grades", x="Grade", y="Sample Size")+
  scale_y_continuous(labels=scales::number_format(scale = 1, accuracy = 1))

print(sampleDist)
```
\end{minipage}
\begin{minipage}[t]{0.45\textwidth}
\vspace{0pt}
As one can see, grade A-, B, C- have the biggest sample size than other grades. The grades were calculated by FiveThirtyEight for each pollster who has its own sample size. Due to the fact that we sum up the sample size, we can conclude that the proportion of the pollsters who receive grade A-, B and C- are greater than those who receive other grades. In addition, we saw that there was a good portion of the sample size that was contributed to the missing grade "none". This portion of the sample therefore does not contribute towards the rating of pollsters. We think that this can reflect the efficiency of the poll. A low portion of the sample size 
\end{minipage}
for the grade "none" indicates that the number of pollsters who gathered those samples and wasn't successfully rated was low. On the other hand, if the sample size for the grade "none" was big, for example if one had most of the samples with "none", then it would mean that the rating mechanism was not successful or the quality of the poll was too low to be used for rating pollsters.
 
### Population
We now take a look at the population type for which the poll was sampled. We saw that the population type "lv", which stands for likely voters, count for most of the sample sizes. This is in accordence with FiveThirtyEight's explanation in their website "Because the database covers the final three weeks of the campaign and almost all polling firms publish likely voter polls by that time, almost all polls in the database should be likely voter surveys.".

```{r, warning=FALSE}
GradeVsPop<-ElectionPoll%>%select(grade, population, samplesize)%>%
  group_by(grade, population)%>%summarise(Size=sum(samplesize), .groups = "drop")%>%na.omit()

popChart <- plot_ly(GradeVsPop, x = ~grade, y = ~population, 
                    type = 'scatter', mode = 'markers', color = ~Size, colors = 'Blues',
                    marker = list(symbol="circle", sizemode = 'diameter', size = ~Size/10000, line = list(width = 2, color = 'black')))%>%
  layout(margin=list(l=0, r=0, b=0, t=40),
         title = 'Population Type VS Grade',
         xaxis = list(showgrid = FALSE),
         showlegend = TRUE,
         paper_bgcolor = 'lightgrey',
         plot_bgcolor = 'lightgrey')

saveWidget(widget = popChart, file = "./Figures/popChart.html")
shots<-webshot(url = "./Figures/popChart.html", file = "./Figures/popChart.png", delay = 1, zoom = 1, vheight = 330, vwidth = 950)
```

![Population Type with Size for Grades](./Figures/popChart.png)

### Poll Rate
We now turn our attention to the actual poll rate for each candidate. Using the end date as the standard, we first drew a time series made of scatter plot of the raw poll rates of the four candidates over time.

```{r}
#Create frame contained time, rawpoll
start_time <- as.POSIXct(ElectionPoll$startdate)
end_time <- as.POSIXct(ElectionPoll$enddate)
prop_raw_clinton <- ElectionPoll$rawpoll_clinton
prop_raw_trump <- ElectionPoll$rawpoll_trump
prop_raw_johnson <- ElectionPoll$rawpoll_johnson
prop_raw_mcmullin <- ElectionPoll$rawpoll_mcmullin

poll_by_time <- data.frame( 
  start_time = start_time,
  end_time = end_time,
  clinton = prop_raw_clinton,
  trump = prop_raw_trump,
  johnson = prop_raw_johnson,
  mcmullin = prop_raw_mcmullin
)

# Order with increasing end_date
poll_by_time <- poll_by_time[order(poll_by_time$end_time, decreasing = FALSE),]
```

```{r, warning=FALSE}
# Plot trend with all four candidates's uncleaned data
g_2 <- ggplot(poll_by_time, aes(x = end_time)) +
  geom_point(aes(y = prop_raw_clinton, color = "Clinton"),size = 1, alpha = 0.3) +
  geom_point(aes(y = prop_raw_trump, color = "Trump"), size = 1, alpha = 0.3) +
  geom_point(aes(y = prop_raw_johnson, color = "Johnson"), size = 1, alpha = 0.3) +
  geom_point(aes(y = prop_raw_mcmullin, color = "Mcmullin"), size = 1, alpha = 0.3) +
  labs(x = "Date", y = "Proportion of rawpoll (%)", 
       title = "Raw Poll Proportion by Time") +
  scale_color_manual(values = c("Clinton" = "blue", "Trump" = "red", "Johnson" = "green", "Mcmullin" = "yellow")) +
  scale_x_datetime(date_breaks = "2 month") +
  theme(axis.text.x = element_text(angle = 0, size = 7, vjust = 0.5)) + 
  theme(axis.title.x = element_text(size = 9, vjust = 0),
        axis.title.y = element_text(size = 9, vjust = 3)) +
  theme(plot.title = element_text(size = 12, face = "bold", 
                                  margin = margin(0, 0, 0, 0))) + 
  theme(legend.title = element_blank()) +
  theme(legend.position = "right")

g_2<-ggplotly(g_2)%>%layout(margin=list(l=0, r=0, b=0, t=30))

saveWidget(widget = g_2, file = "./Figures/dotChart.html")
shots<-webshot(url = "./Figures/dotChart.html", file = "./Figures/dotChart.png", delay = 1, zoom = 2, vheight = 290)
```

![Raw Poll Proportion by Time](./Figures/dotChart.png)

Figure 4 indicates that Clinton and Trumpâ€™s approval ratings are significantly higher than those of Johnson and Mcmullin at the overall level. Another interesting demonstration is the divergence of support as the vote draws to a close. This shows that as the voting deadline approaches, people's intentions are more inclined to one of Clinton or Trump.

Voting is more polarized. A low poll rate for one candidate also implies that other candidates may have high poll rates. This creates differences in each state. Therefore, we try to compare each candidate's poll result in each state. We processed the metadata by counting the polls of four candidates in each state respectively. Result is easy to obtain by multiplying the given sample size and proportion. Regardless of the various pollsters, we combine the number of polls for each candidate received in each state. In this case, we treat NA as 0.

```{r}
#Create frame contained state, poll number for each candidate
states <- ElectionPoll$state
prop_raw_clinton <- ElectionPoll$rawpoll_clinton
prop_raw_trump <- ElectionPoll$rawpoll_trump
prop_raw_johnson <- ElectionPoll$rawpoll_johnson
prop_raw_mcmullin <- ElectionPoll$rawpoll_mcmullin
size <- ElectionPoll$samplesize

poll_by_state <- data.frame(
  state = states,
  prop_clinton = prop_raw_clinton,
  prop_trump = prop_raw_trump,
  prop_johnson = prop_raw_johnson,
  prop_mcmullin = prop_raw_mcmullin,
  size = size,
  NumVote_clinton = size * (prop_raw_clinton/100),
  NumVote_trump = size * (prop_raw_trump/100),
  NumVote_johnson = size * (prop_raw_johnson/100),
  NumVote_mcmullin = size * (prop_raw_mcmullin/100)
)

poll_by_state[is.na(poll_by_state)] <- 0

NumVote_State <- cbind(poll_by_state$state, poll_by_state$NumVote_clinton, 
                       poll_by_state$NumVote_trump, poll_by_state$NumVote_johnson, 
                       poll_by_state$NumVote_mcmullin)
colnames(NumVote_State) <- c("state","Clinton", "Trump", "Johnson", "Mcmullin")

NumVoteState <- as.data.frame(NumVote_State) %>%
  pivot_longer(cols = -state,
               names_to = "candidate",
               values_to = "PollNumber")
NumVoteState$PollNumber <- as.numeric(NumVoteState$PollNumber)
```

\begin{minipage}[t]{0.7\textwidth}
```{r, out.width="100%", out.height="70%", fig.cap = "Poll Percentage by States"}
g_11 <- ggplot(data = NumVoteState, mapping = aes( x = state, fill = candidate)) +
  geom_col(aes(y = PollNumber),position='fill') +
  labs(x = "State", y = "Proportion", 
       title = "Poll Percentage by States") +
  scale_fill_manual(values=c("Clinton" = "blue", "Trump" = "red", 
                             "Johnson" = "green", "Mcmullin" = "yellow")) +
  theme(axis.text.x = element_text(angle = 90, size = 6, vjust = 0.5)) + 
  theme(axis.title.x = element_text(size = 9, vjust = 0),
        axis.title.y = element_text(size = 9, vjust = 3)) + 
  theme(plot.title = element_text(size = 12, face = "bold", 
                                  margin = margin(0, 0, 0, 0))) +
  theme(legend.position = "bottom")
print(g_11)
```
\end{minipage}
\begin{minipage}[t]{0.3\textwidth}
\vspace{0pt}
Figure 5 shows the poll proportions of the four candidates in each state distinguished by colors. We can clearly observe which candidate is likely to win all the electoral votes in each state, which is helpful in estimating the outcome of the presidential election. From the chart above, we conclude that Clinton and Trump are clearly ahead of Johnson and Mcmullin. Furthermore, Clinton is clearly ahead of Trump in states like California, DC and Hawaii etc. On the nother side, Trump is ahead of Clinton in Alabama, Alaska and Idaho etc. This helps us explore the leading candidates in each state.
\end{minipage}


We now look at the time series of the adjusted poll proportion in Figure 5 below.

```{r, warning=FALSE}
#Create frame contained time, rawpoll
poll_by_time <- ElectionPoll%>%transmute(end_time=as.POSIXct(enddate),
                                         clinton=adjpoll_clinton, trump=adjpoll_trump, johnson=adjpoll_johnson, mcmullin=adjpoll_mcmullin )%>%arrange(end_time)

# Plot trend with all four candidates's uncleaned data
g_1 <- ggplot(poll_by_time, aes(x = end_time)) +
  geom_line(aes(y = clinton, color = "Clinton"), alpha = 0.6) +
  geom_line(aes(y = trump, color = "Trump"), alpha = 0.6) +
  geom_line(aes(y = johnson, color = "Johnson"), alpha = 0.6) +
  geom_line(aes(y = mcmullin, color = "Mcmullin"), alpha = 0.6) +
  labs(x = "Date", y = "Proportion of rawpoll (%)", 
       title = "Adjusted Poll Proportion by Time") +
  scale_color_manual(values = c("Clinton" = "blue", "Trump" = "red", "Johnson" = "darkgreen", "Mcmullin" = "yellow")) +
  scale_x_datetime(date_breaks = "2 month") +
  theme(axis.text.x = element_text(angle = 0, size = 7, vjust = 0.5)) + 
  theme(axis.title.x = element_text(size = 9, vjust = 0),
        axis.title.y = element_text(size = 9, vjust = 3)) +
  theme(plot.title = element_text(size = 12, face = "bold", 
                                  margin = margin(0, 0, 0, 0))) +
  theme(legend.title = element_blank())
g_1<-ggplotly(g_1)%>%layout(margin=list(l=0, r=0, b=0, t=30))

saveWidget(widget = g_1, file = "./Figures/TsChart.html")
shots<-webshot(url = "./Figures/TsChart.html", file = "./Figures/TsChart.png", delay = 1, zoom = 2, vheight = 290)
```

![Adjusted Poll Percentage by Time](./Figures/TsChart.png)

We immediately noticed that some of the poll rate for Johnson fell below zero. We did not find a detailed justification to the adjustment they have made from their website, therefore, this makes us to question the validity of the adjusted poll result done by FiveThirtyEight. 

For other candidates the adjustment was not posing the negativeness issue, so we want to explore if the adjusted data can be ignored or if it actually brings some improvements than the raw poll data. Since the final two candidates in Election 2016 are Clinton and Trump, we plotted box plots of the difference of their poll results, one for the raw poll and one for the adjusted poll. 

```{r}
fig1<-ElectionPoll%>%mutate(Diffs=rawpoll_clinton - rawpoll_trump)%>%plot_ly(y=~Diffs, color = ~grade, type = "box")%>%layout()
fig2<-ElectionPoll%>%mutate(Diffs=adjpoll_clinton - adjpoll_trump)%>%plot_ly(y=~Diffs, color = ~grade, type = "box",showlegend=FALSE)

boxchart<-subplot(fig1, fig2, nrows = 2, shareX = TRUE)%>%
  layout(margin=list(l=0, r=0, b=0, t=30),
         yaxis=list(title="Raw Poll Difference"),
         yaxis2=list(title="Adjusted Poll Difference"),
         title="Difference between poll_Clinton and poll_Trump",
         legend = list(title = list(text="Grade")))

saveWidget(widget = boxchart, file = "./Figures/boxchart.html")
shots<-webshot(url = "./Figures/boxchart.html", file = "./Figures/boxchart.png", delay = 1, zoom = 2, vheight = 500)
```

![Boxchart of Difference between Polls](./Figures/boxchart.png)

We saw that there's little difference between the distribution of the raw and the adjusted data. However, the mean of each grade of the adjusted poll result was a little closer to zero than that of the raw poll result. This indicated that the adjustment that FiveThirtyEight made was a slight improvement because the raw poll difference of each grade was mostly above zero, which showed that the poll result was more in favour of Clinton yet Trump was the final winner of the election.

However, due to the fact that FiveThirtyEight's adjustment to the poll result yields negative values, we think it is therefore unreasonable to do such adjustment. It gives the reader a difficulty in interpreting this adjustment.

Finally we plot the cumulative mean of the raw poll result for the final two candidates, Trump and Clinton. We selected the Clinton and Trump polls and ignore the other candidates' poll since the other candidates are polling far behind Clinton and Trump. From Figure 7 below we see that the overall national poll result indicates that Clinton should be the winner of the election. However, some of the individual states resulted the opposite conclusion. It it therefore hard to tell which candidate is leading by examining the individual state poll result.


```{r}
#Calculate cumulative mean
rMean<-function(df){
  rMeans<-df%>%group_by(enddate) %>%
    summarize(mean_trump = mean(rawpoll_trump), mean_clinton=mean(rawpoll_clinton))%>%
    transmute(enddate=enddate, rMean_trump=cummean(mean_trump), rMean_clinton=cummean(mean_clinton))%>%
    gather(key="Candidate", value="val", rMean_trump:rMean_clinton)
  return(data.frame(rMeans))
}
#Plot cumulative mean for a State
PlotCMean<-function(state){
  p<-plot_ly(Navg_lst[[state]], x=~enddate, y=~val, color=~Candidate, name = ~paste(state, ":", Candidate))%>%add_lines()%>%
    layout(title="plot",
           xaxis=list(tickfont = list(size = 8)),
           legend = list(font=list(size = 8))
    )
  return(p)
}
#Clean the data
CMeanData<-ElectionPoll
CMeanData[which(CMeanData$state=="Maine CD-1"),"state"]<-"Maine"
CMeanData[which(CMeanData$state=="Maine CD-2"),"state"]<-"Maine"
CMeanData[which(CMeanData$state=="Nebraska CD-1"),"state"]<-"Nebraska"
CMeanData[which(CMeanData$state=="Nebraska CD-2"),"state"]<-"Nebraska"
CMeanData[which(CMeanData$state=="Nebraska CD-3"),"state"]<-"Nebraska"
#apply rMean to all states
Navg_lst<-CMeanData%>%select(state, enddate, rawpoll_trump, rawpoll_clinton)%>%arrange(.by=enddate, decreasing=FALSE)%>%split(.$state)
Navg_lst<-purrr::map(Navg_lst, rMean)
#sample a few states
set.seed(100)
state_i<-sample(names(Navg_lst), size=3, replace = FALSE)
#make subplot
cMeanchart<-subplot(PlotCMean("U.S."),PlotCMean(state_i[1]),PlotCMean(state_i[2]),PlotCMean(state_i[3]),nrows = 2)%>%
  layout(margin=list(l=0, r=0, b=0, t=30),
         title="Time Series of Cumulative Mean of Trump and Clinton Poll Result",
         annotations=list( 
           list( 
             x = 0.2,  
             y = 0.85,  
             text = "U.S.", 
             font=list(size = 12),
             xref = "paper",  
             yref = "paper",  
             xanchor = "center",  
             showarrow = FALSE 
           ),  
           list( 
             x = 0.75,  
             y = 0.85,  
             text = state_i[1],  
             font=list(size = 12),
             xref = "paper",  
             yref = "paper",  
             xanchor = "center",
             showarrow = FALSE 
           ),
           list( 
             x = 0.2,  
             y = 0.3,  
             text = state_i[2],  
             font=list(size = 12),
             xref = "paper",  
             yref = "paper",  
             xanchor = "center",
             showarrow = FALSE 
           ),
           list( 
             x = 0.75,  
             y = 0.3,  
             text = state_i[3],  
             font=list(size = 12),
             xref = "paper",  
             yref = "paper",  
             xanchor = "center",
             showarrow = FALSE 
           )
         ),
         showlegend = TRUE
  )
saveWidget(widget = cMeanchart, file = "./Figures/cMeanchart.html") 
shots<-webshot(url = "./Figures/cMeanchart.html", file = "./Figures/cMeanchart.png", delay = 1, zoom = 2, vheight = 400)
```

![Cumulative Mean of Raw Poll Result](./Figures/cMeanchart.png)

### Map Chart of Data

```{r}
#fill a matrix
ElectionPoll$state<-toupper(ElectionPoll$state)
state_poll<- ElectionPoll %>%
  group_by(state) %>%
  summarise(rawpoll_clinton = mean(rawpoll_clinton), rawpoll_trump = mean(rawpoll_trump),adjpoll_clinton = mean(adjpoll_clinton), adjpoll_trump = mean(adjpoll_trump))
#delete useless data
state_poll<-state_poll[-50,]
state_poll<-state_poll[-c(31:33),]
state_poll<-state_poll[-c(21:22),]
colnames(state_poll)<-c("State","rawpoll_clinton","rawpoll_trump","adjpoll_clinton","adjpoll_trump","percent_rawpoll_clinton","percent_adjpoll_clinton")

state_rawpoll<-data.frame(state_poll[,1:3])
state_adjpoll<-data.frame(state_poll[,1],state_poll[,4:5])
#add percent
state_rawpoll$percent_rawpoll_clinton<-100*state_poll$rawpoll_clinton/(state_poll$rawpoll_clinton+state_poll$rawpoll_trump)
state_adjpoll$percent_adjpoll_clinton<-100*state_poll$adjpoll_clinton/(state_poll$adjpoll_clinton+state_poll$adjpoll_trump)
```

To make state-by-state polling results more visible, we've reflected the candidates' polling shares on a map of the United States. 

:::::: {.cols data-latex=""}

::: {.col data-latex="{0.6\textwidth}"}
```{r}
#get map data:
df <- read.csv("https://raw.githubusercontent.com/plotly/datasets/master/us-cities-top-1k.csv")
df<-distinct(df,State, .keep_all = TRUE)
df$State<-toupper(df$State)
df<-df[,-3]
df<-df[,-1]
states_map <- map_data(map = "state",region =df$State)

#get mean longitude and latitude
region.lab.data <- states_map %>%
  group_by(region) %>%
  summarise(lon = mean(long), lat = mean(lat))
region.lab.data$region<-toupper(region.lab.data$region)

region.lab.data[which(region.lab.data$region=="HAWAII"),]<-df[which(df$State=="HAWAII"),]
region.lab.data[which(region.lab.data$region=="ALASKA"),]<-df[which(df$State=="ALASKA"),]
colnames(region.lab.data)<-c("State","lat","lon")

df1<-merge(state_rawpoll,df, by.x = "State")
df_1<-merge(state_adjpoll,df, by.x = "State")

#add code
df2<-read.csv("https://raw.githubusercontent.com/plotly/datasets/master/2011_us_ag_exports.csv")
df2<-distinct(df2,state, .keep_all = TRUE)
df2$state<-toupper(df2$state)
df2<-df2[, 1:2]
colnames(df2)<-c("Code", "State")
df2<-rbind(df2, data.frame(Code="DC", State="DISTRICT OF COLUMBIA"))

df3<-merge(df1, df2, by.x = "State")
df_3<-merge(df_1, df2, by.x = "State")

#choropleth plot
g <- list(
  scope = 'usa',
  projection = list(type = 'albers usa')
)

mapchart1<-plot_geo(df3, locationmode = 'USA-states')%>% 
  add_trace(z = ~percent_rawpoll_clinton, locations = ~Code, color =~percent_rawpoll_clinton, colors=c('indianred','white','skyblue'),
            colorbar=list(limits = c(0, 100),title = list(text="Clinton's vote share(%)", font=list(size=8)),
                          x = 1,y = 0.7,len = 0.4))%>%
  add_trace(type = "scattergeo", locationmode = 'USA-states', locations = ~Code, 
            text = ~Code, mode = "text", textfont = list(size = 6))%>%
  layout(geo = g)


#adjpoll
mapchart2<-plot_geo(df_3, locationmode = 'USA-states')%>% 
  add_trace(z = ~percent_adjpoll_clinton, locations = ~Code, color =~percent_adjpoll_clinton, colors=c('indianred','white','skyblue'),showscale=FALSE)%>%
  add_trace(type = "scattergeo", locationmode = 'USA-states', locations = ~Code, 
            text = ~Code, mode = "text", textfont = list(size = 6))%>%
  layout(geo = g, showlegend=FALSE)

mapchart_1_2<-subplot(mapchart1, mapchart2, nrows = 2)%>%
  layout(margin=list(l=0, r=0, b=0, t=20),
         title=list(text="Clinton and Trump Predicted Vote Share in 2016 Election", 
                    font=list(size=10)),
         annotations=list( 
           list( 
             x = 0.5,  
             y = 1,  
             text = "Raw Poll", 
             font=list(size = 10),
             xref = "paper",  
             yref = "paper",  
             xanchor = "center",  
             showarrow = FALSE 
           ),  
           list( 
             x = 0.5,  
             y = 0.5,  
             text = "Adjusted Poll",  
             font=list(size = 10),
             xref = "paper",  
             yref = "paper",  
             xanchor = "center",
             showarrow = FALSE 
           )), showlegend=FALSE)

saveWidget(widget = mapchart_1_2, file = "./Figures/mapchart_1_2.html") 
shots<-webshot(url = "./Figures/mapchart_1_2.html", file = "./Figures/mapchart_1_2.png", delay = 2, zoom = 2, vheight = 600, vwidth = 500)
```

![Map Chart of Vote Shares of Candidates by States](./Figures/mapchart_1_2.png)
:::

::: {.col data-latex="{0.02\textwidth}"}
\ 
<!-- an empty Div (with a white space), serving as
a column separator -->
:::

::: {.col data-latex="{0.38\textwidth}"}
In the contour plot Figure 9 on the left, blue indicates that Clinton is polling proportionally greater than Trump, and red indicates that Trump is polling proportionally greater than Clinton. The darker the color, the higher the proportions are. For states that are nearly white, the margin of victory is nearly half between Trump and Clinton.

\vspace{13pt}

We again saw that there was little difference between the results using the raw poll data and the adjusted poll data, which further support our opinion that the adjustment made by FiveThirtyEight must be carefully justified by readers because of its negative values. We then saw from the map in Figure 9 that Clinton seems to dominate the public opinions because the colors of states are a bit closer to white and pale red.
:::
::::::

Furthermore, we want to find out exactly the states which Clinton or Trump captured all of the electoral votes. The visualization below shows the net polls generated by each state for Clinton and Trump. 
\begin{minipage}[t]{0.7\textwidth}
```{r, out.width="100%", fig.cap = "Net Polls by States."}
# Calculate net polls
poll_gap <- NumVoteState%>%filter(candidate %in% c("Clinton", "Trump"))%>%
  group_by(state, candidate)%>%summarize(numP=sum(PollNumber), .groups="drop")%>%
  spread(key=candidate, value=numP)%>%transmute(state=state, gap=Clinton-Trump)

# plot net polls by state(remove "U.S.")
poll_gap$pos <- poll_gap$gap > 0
poll_gap$pos[poll_gap$pos == TRUE] <- "Clinton exceeds Trump"
poll_gap$pos[poll_gap$pos == FALSE] <- "Trump exceeds Clinton"
poll_gap <- poll_gap %>%filter(state != "U.S.")

g_13 <- ggplot(data = poll_gap, aes(x = state, y = gap, fill = pos)) + 
  geom_bar(stat="identity") + 
  labs(x = "State", y = "Poll gap", fill = "Leading",
       title = "Net Polls by States") +
  scale_fill_manual(values=c("Clinton exceeds Trump" = "blue", "Trump exceeds Clinton" = "red")) +
  theme(axis.text.x = element_text(angle = 90, size = 6, vjust = 0.5)) + 
  theme(axis.title.x = element_text(size = 9, vjust = 0),
        axis.title.y = element_text(size = 9, vjust = 3)) + 
  theme(plot.title = element_text(size = 12, face = "bold", 
                                  margin = margin(0, 0, 0, 0))) +
  theme(legend.position = c(1, 1), legend.justification = c(1, 1))
g_13
```
\end{minipage}
\begin{minipage}[t]{0.3\textwidth}
\vspace{0pt}
Based on raw poll data, Figure 10 shows Clinton won 27 constituencies including 25 states, one additional Maine district and DC. Trump won 25 states plus one additional district in Maine and three additional districts in Nebraska. It is not difficult to see from Figure 10 that Maine and Nebraska have two and three additional electoral district respectively in addition to their own states. The candidate with the most votes in Maine and Nebraska will receive two electoral votes,
\end{minipage}
and the remaining electoral votes will be allocated to the presidential candidate who wins each district. Moreover, DC have three electoral votes as an independent district.

Finally, we take a look at the map chart of the electoral votes based on raw poll result. We use the poll opinion to generate a map showing the predicted election result, and we compare it with the counterpart showing the actual final election result. 

The Electoral College in the United States consists of 538 electoral votes. These electoral votes are distributed among the 50 states and the District of Columbia based on the total number of members in Congress, which includes both the House of Representatives and the Senate. There are 435 members in the U.S. House of Representatives. Each state is given a number of electoral votes equal to its total number of representatives in the House and it is based on the state's population. The minimum number of electoral votes a state can have is 3. Then there are 100 members in the U.S. Senate, with each state having two senators regardless of its population. Therefore, each state is allocated two additional electoral votes based on its Senate representation. Finally we have the District of Columbia. Although the District of Columbia is not a state, it is granted three electoral votes as if it were a state of the U.S.. In total, the number of electoral votes is 435 (House of Representatives) + 100 (Senate) + 3 (District of Columbia) = 538 electoral votes.

To win the U.S. presidential election, a candidate must secure a majority of these electoral votes, which is currently 270 electoral votes. This system often leads to a focus on swing states or battleground states where the outcome is less predictable, as candidates aim to accumulate enough electoral votes to win the election. In our Figure 9 map chart, these states tend to have a pale colour due to its swing opinion. 

We obtained the final election result from [@Final]. 

:::::: {.cols data-latex=""}
::: {.col data-latex="{0.6\textwidth}"}
```{r}
poll_gap$state<-toupper(poll_gap$state)
poll_gap[which(poll_gap$state %in% c("MAINE CD-1", "MAINE CD-2")),"state"]<-"MAINE"
poll_gap[which(poll_gap$state %in% c("NEBRASKA CD-1", "NEBRASKA CD-2", "NEBRASKA CD-3")),"state"]<-"NEBRASKA"

poll_gap<-poll_gap%>%group_by(state)%>%summarize(gap=sum(gap))%>%
  transmute(State=state, PredictedResult=ifelse(gap>0, "C", "T"))

#election result in the end
electionresult<-read.csv("electionresult.csv")
electionresult$State<-toupper(electionresult$State)
df_4<-merge(df_3,electionresult,by.x="State")%>%mutate(bin=ifelse(Result=="C", 0, 100))
df_4<-inner_join(df_4, poll_gap, by="State")%>%mutate(Predictedbin=ifelse(PredictedResult=="C", 0, 100))

mapchart3<-plot_geo(df_4, locationmode = 'USA-states')%>% 
  add_trace(z = ~bin, locations = ~Code, color =~bin, colors=c("skyblue", 'white', 'red'),
            colorbar=list(limits = c(0, 100),title = list(text="Trump wins in this state", font=list(size=8)),
                          x = 1,y = 0.7,len = 0.4)
  )%>%
  add_trace(type = "scattergeo", locationmode = 'USA-states', locations = ~Code, 
            text = ~Number, mode = "text",textfont = list(size = 6))%>%
  layout(geo = g)


mapchart4<-plot_geo(df_4, locationmode = 'USA-states')%>% 
  add_trace(z = ~Predictedbin, locations = ~Code, color =~Predictedbin, 
            colors=c("skyblue", 'white', 'red'), showscale=FALSE)%>%
  add_trace(type = "scattergeo", locationmode = 'USA-states', locations = ~Code, 
            text = ~Number, mode = "text",textfont = list(size = 6))%>%
  layout(geo = g, showlegend=FALSE)

mapchart_3_4<-subplot(mapchart3, mapchart4, nrows=2)%>%
  layout(margin=list(l=0, r=0, b=0, t=20),
         title =list(text="Clinton and Trump Vote Share in 2016 Election", 
                     font=list(size=10)),
         annotations=list( 
           list( 
             x = 0.5,  
             y = 1,  
             text = "2016 Final Presidential Election Results", 
             font=list(size = 8),
             xref = "paper",  
             yref = "paper",  
             xanchor = "center",  
             showarrow = FALSE 
           ),  
           list( 
             x = 0.5,  
             y = 0.5,  
             text = "2016 Predicted Presidential Election Results",  
             font=list(size = 8),
             xref = "paper",  
             yref = "paper",  
             xanchor = "center",
             showarrow = FALSE 
           )), 
         showlegend=FALSE)

saveWidget(widget = mapchart_3_4, file = "./Figures/mapchart_3_4.html") 
shots<-webshot(url = "./Figures/mapchart_3_4.html", file = "./Figures/mapchart_3_4.png", delay = 2, zoom = 2, vheight = 400, vwidth = 500)
```

![Map Chart of Election Result 2016](./Figures/mapchart_3_4.png)
:::

::: {.col data-latex="{0.02\textwidth}"}
\ 
<!-- an empty Div (with a white space), serving as
a column separator -->
:::

::: {.col data-latex="{0.38\textwidth}"}
From the Figure 11 we can see that the actual final election outcome was almost the entire opposite to the predicted result. In 2016, Trump won 304 votes compared to 227 votes for Hillary Clinton, which was not predicted by the election poll result. Therefore, readers must be careful about the election poll. There have been some criticisms on the usefulness of these polls [@Critic, @Critic2]. From the previous analysis in Figure 1, we were also able to find out that over half of the pollster ratings were between B+ to C and none. This might suggests that public opinion polls are not as reliable as one would expect due to the quality of the pollsters.
:::
::::::


# Conclusion
In the visual analysis, the following key observations and conclusions were made:

1. Regarding the overall prediction results, grades ranging from A+ to B- accounted for nearly half of the total, while samples with no ratings constituted just over 15%. This indicates a reasonably distributed outcome across different grade levels in the predictions.

2. The sample size alone does not determine the quality of predictions. Other factors, such as data quality and analysis methods, also play a crucial role in prediction accuracy.

3. The analysis revealed that the support rates for Clinton and Trump were significantly higher than those for Johnson and McMullin. Consequently, the subsequent analysis focused on the top two candidates.

4. The mean of the adjusted voting results was closer to zero than that of the raw voting results. This suggests that data adjustments can reduce biases and enhance the accuracy of the analysis.

5. The majority of predictions across different states in the U.S. indicated a likely victory for Clinton, reflecting a prevailing trend in the forecasts.

6. When examining the adjusted data, it was found that states predicting a Trump victory showed a clear advantage for Trump in the actual voting results. Similarly, states predicting a Clinton victory reflected a narrow win for Clinton in the actual vote.

7. A comparison between the final results and predictions based on raw data showed that outcomes in six states were contrary to the predictions. These states had very close vote counts for Clinton and Trump in the forecasts. Using adjusted data for predictions might yield results closer to the actual outcomes.

In summary, it can be concluded that for certain states' election results, predictions based on adjusted data may be more accurate. Sample size is not the sole determinant of prediction quality; other factors such as data quality and analysis methods should also be considered. Additionally, a state-specific analysis contributes to a more comprehensive understanding of election outcomes.

# References